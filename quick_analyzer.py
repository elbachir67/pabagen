#!/usr/bin/env python3
"""
Analyseur rapide du repository existant
Version simplifi√©e pour ex√©cution imm√©diate
"""

import os
import sys
import ast
import json
import time
import subprocess
from pathlib import Path
from typing import Dict, List, Any, Optional

class QuickRepositoryAnalyzer:
    """Analyseur rapide et simple du repository"""
    
    def __init__(self):
        self.repo_url = "https://github.com/elbachir67/trans-neur-emb-sem-pre-meta-trans.git"
        self.repo_name = "trans-neur-emb-sem-pre-meta-trans"
        self.analysis_results = {}
    
    def clone_or_update_repo(self) -> bool:
        """Clone le repository ou le met √† jour s'il existe"""
        print("üîÑ V√©rification/clonage du repository...")
        
        if os.path.exists(self.repo_name):
            print(f"‚úÖ Repository {self.repo_name} trouv√© localement")
            
            # V√©rifier si c'est un repo git
            if os.path.exists(os.path.join(self.repo_name, '.git')):
                print("üîÑ Mise √† jour du repository...")
                try:
                    os.chdir(self.repo_name)
                    subprocess.run(['git', 'pull'], check=True, capture_output=True)
                    print("‚úÖ Repository mis √† jour")
                    os.chdir('..')
                    return True
                except subprocess.CalledProcessError:
                    print("‚ö†Ô∏è  Impossible de mettre √† jour - continuons avec la version locale")
                    os.chdir('..')
                    return True
                except FileNotFoundError:
                    print("‚ö†Ô∏è  Git non trouv√© - continuons avec la version locale")
                    return True
            else:
                print("‚ö†Ô∏è  R√©pertoire existe mais n'est pas un repo Git")
                return True
        else:
            print(f"üì• Clonage du repository depuis {self.repo_url}")
            try:
                subprocess.run(['git', 'clone', self.repo_url], check=True)
                print("‚úÖ Repository clon√© avec succ√®s")
                return True
            except subprocess.CalledProcessError as e:
                print(f"‚ùå Erreur lors du clonage: {e}")
                print("üí° V√©rifiez votre connexion internet et que Git est install√©")
                return False
            except FileNotFoundError:
                print("‚ùå Git non trouv√©. Veuillez installer Git pour cloner le repository")
                print("üí° Ou t√©l√©chargez manuellement le repository depuis GitHub")
                return False
    
    def analyze_repository(self) -> Dict[str, Any]:
        """Analyse le repository"""
        repo_path = Path(self.repo_name)
        
        if not repo_path.exists():
            print(f"‚ùå Repository non trouv√©: {repo_path}")
            return {}
        
        print(f"üîç Analyse du repository: {repo_path}")
        
        analysis = {
            'repository_path': str(repo_path),
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'files': {
                'total': 0,
                'python': [],
                'other': []
            },
            'code_metrics': {
                'total_lines': 0,
                'python_files_count': 0
            },
            'python_structure': {
                'classes': [],
                'functions': [],
                'imports': set()
            },
            'key_components': {
                'token_pair_related': [],
                'embedding_related': [],
                'evaluation_related': [],
                'model_related': []
            },
            'errors': [],
            'recommendations': []
        }
        
        # Scanner tous les fichiers
        for file_path in repo_path.rglob("*"):
            if file_path.is_file():
                analysis['files']['total'] += 1
                
                if file_path.suffix == '.py':
                    rel_path = str(file_path.relative_to(repo_path))
                    analysis['files']['python'].append(rel_path)
                    analysis['code_metrics']['python_files_count'] += 1
                    
                    # Analyser le fichier Python
                    self._analyze_python_file(file_path, repo_path, analysis)
                else:
                    analysis['files']['other'].append(str(file_path.relative_to(repo_path)))
        
        # Convertir les sets en listes pour JSON
        analysis['python_structure']['imports'] = list(analysis['python_structure']['imports'])
        
        # G√©n√©rer des recommandations
        self._generate_recommendations(analysis)
        
        self.analysis_results = analysis
        return analysis
    
    def _analyze_python_file(self, file_path: Path, repo_path: Path, analysis: Dict):
        """Analyse un fichier Python sp√©cifique"""
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
                lines = len(content.split('\n'))
                analysis['code_metrics']['total_lines'] += lines
                
                # Parser l'AST
                try:
                    tree = ast.parse(content)
                    self._extract_ast_info(tree, file_path, repo_path, analysis)
                except SyntaxError as e:
                    error_msg = f"Erreur syntaxe dans {file_path.relative_to(repo_path)}: {e}"
                    analysis['errors'].append(error_msg)
                    
        except Exception as e:
            error_msg = f"Erreur lecture {file_path.relative_to(repo_path)}: {e}"
            analysis['errors'].append(error_msg)
    
    def _extract_ast_info(self, tree: ast.AST, file_path: Path, repo_path: Path, analysis: Dict):
        """Extrait les informations de l'AST"""
        rel_file_path = str(file_path.relative_to(repo_path))
        
        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef):
                class_info = {
                    'name': node.name,
                    'file': rel_file_path,
                    'methods': [m.name for m in node.body if isinstance(m, ast.FunctionDef)],
                    'line_count': getattr(node, 'end_lineno', 1) - getattr(node, 'lineno', 1)
                }
                analysis['python_structure']['classes'].append(class_info)
                
                # Cat√©goriser les classes importantes
                class_name_lower = node.name.lower()
                if 'token' in class_name_lower or 'pair' in class_name_lower:
                    analysis['key_components']['token_pair_related'].append(class_info)
                elif 'embed' in class_name_lower:
                    analysis['key_components']['embedding_related'].append(class_info)
                elif 'eval' in class_name_lower or 'assess' in class_name_lower:
                    analysis['key_components']['evaluation_related'].append(class_info)
                elif 'model' in class_name_lower:
                    analysis['key_components']['model_related'].append(class_info)
            
            elif isinstance(node, ast.FunctionDef):
                # Fonctions au niveau module (pas dans une classe)
                function_info = {
                    'name': node.name,
                    'file': rel_file_path,
                    'args': [arg.arg for arg in node.args.args],
                    'line_count': getattr(node, 'end_lineno', 1) - getattr(node, 'lineno', 1)
                }
                analysis['python_structure']['functions'].append(function_info)
            
            elif isinstance(node, ast.Import):
                for alias in node.names:
                    analysis['python_structure']['imports'].add(alias.name)
            
            elif isinstance(node, ast.ImportFrom):
                if node.module:
                    analysis['python_structure']['imports'].add(node.module)
    
    def _generate_recommendations(self, analysis: Dict):
        """G√©n√®re des recommandations bas√©es sur l'analyse"""
        recommendations = []
        
        # √âvaluer la complexit√©
        total_classes = len(analysis['python_structure']['classes'])
        total_functions = len(analysis['python_structure']['functions'])
        
        if total_classes > 10:
            recommendations.append("üü¢ Bon nombre de classes d√©tect√©es - Code bien structur√©")
        elif total_classes > 0:
            recommendations.append("üü° Structure modulaire de base pr√©sente")
        else:
            recommendations.append("üî¥ Peu de classes trouv√©es - Code potentiellement proc√©dural")
        
        # √âvaluer les composants cl√©s
        key_components = analysis['key_components']
        if key_components['token_pair_related']:
            recommendations.append("‚úÖ Composants TokenPair trouv√©s - R√©utilisation possible")
        if key_components['embedding_related']:
            recommendations.append("‚úÖ Composants Embedding trouv√©s - Base solide pour extension")
        if key_components['evaluation_related']:
            recommendations.append("‚úÖ Composants d'√©valuation trouv√©s - M√©triques existantes")
        
        # √âvaluer les d√©pendances
        imports = analysis['python_structure']['imports']
        ml_deps = [imp for imp in imports if any(keyword in imp.lower() 
                  for keyword in ['torch', 'transform', 'sklearn', 'numpy'])]
        if ml_deps:
            recommendations.append("‚úÖ D√©pendances ML d√©tect√©es - Compatible avec notre approche")
        
        # √âvaluer la qualit√©
        if len(analysis['errors']) == 0:
            recommendations.append("‚úÖ Code sans erreurs de parsing - Qualit√© √©lev√©e")
        elif len(analysis['errors']) < 5:
            recommendations.append("‚ö†Ô∏è  Quelques erreurs mineures d√©tect√©es")
        else:
            recommendations.append("üî¥ Nombreuses erreurs d√©tect√©es - Code n√©cessitant attention")
        
        # Recommandations d'int√©gration
        if (len(key_components['token_pair_related']) > 0 and 
            len(key_components['embedding_related']) > 0):
            recommendations.append("üéØ Strat√©gie recommand√©e: Extension par h√©ritage")
        elif total_classes > 5:
            recommendations.append("üéØ Strat√©gie recommand√©e: Adaptation avec adaptateurs")
        else:
            recommendations.append("üéØ Strat√©gie recommand√©e: Impl√©mentation propre avec inspiration")
        
        analysis['recommendations'] = recommendations
    
    def print_analysis_report(self):
        """Affiche le rapport d'analyse"""
        if not self.analysis_results:
            print("‚ùå Aucune analyse disponible")
            return
        
        analysis = self.analysis_results
        
        print("\n" + "="*70)
        print("üìä RAPPORT D'ANALYSE DU REPOSITORY")
        print("="*70)
        
        print(f"üìÅ Repository: {analysis['repository_path']}")
        print(f"üïí Analys√© le: {analysis['timestamp']}")
        print(f"üìÑ Fichiers totaux: {analysis['files']['total']}")
        print(f"üêç Fichiers Python: {analysis['code_metrics']['python_files_count']}")
        print(f"üìù Lignes de code: {analysis['code_metrics']['total_lines']:,}")
        
        print(f"\nüèóÔ∏è  STRUCTURE PYTHON")
        print(f"   Classes: {len(analysis['python_structure']['classes'])}")
        print(f"   Fonctions: {len(analysis['python_structure']['functions'])}")
        print(f"   Imports uniques: {len(analysis['python_structure']['imports'])}")
        
        print(f"\nüéØ COMPOSANTS CL√âS IDENTIFI√âS")
        key_components = analysis['key_components']
        print(f"   TokenPair related: {len(key_components['token_pair_related'])}")
        print(f"   Embedding related: {len(key_components['embedding_related'])}")
        print(f"   Evaluation related: {len(key_components['evaluation_related'])}")
        print(f"   Model related: {len(key_components['model_related'])}")
        
        # Afficher les classes importantes
        if key_components['token_pair_related']:
            print(f"\nüîë CLASSES TOKEN PAIR")
            for cls in key_components['token_pair_related'][:5]:
                print(f"   ‚Ä¢ {cls['name']} ({len(cls['methods'])} m√©thodes) - {cls['file']}")
        
        if key_components['embedding_related']:
            print(f"\nüß† CLASSES EMBEDDING")
            for cls in key_components['embedding_related'][:5]:
                print(f"   ‚Ä¢ {cls['name']} ({len(cls['methods'])} m√©thodes) - {cls['file']}")
        
        # D√©pendances importantes
        important_imports = [imp for imp in analysis['python_structure']['imports'] 
                           if any(keyword in imp.lower() 
                                 for keyword in ['torch', 'transform', 'sklearn', 'numpy', 'pandas'])]
        if important_imports:
            print(f"\nüì¶ D√âPENDANCES IMPORTANTES")
            for imp in sorted(important_imports)[:10]:
                print(f"   ‚Ä¢ {imp}")
        
        # Erreurs
        if analysis['errors']:
            print(f"\n‚ö†Ô∏è  ERREURS D√âTECT√âES ({len(analysis['errors'])})")
            for error in analysis['errors'][:3]:
                print(f"   ‚Ä¢ {error}")
            if len(analysis['errors']) > 3:
                print(f"   ... et {len(analysis['errors']) - 3} autres")
        
        # Recommandations
        print(f"\nüí° RECOMMANDATIONS")
        for rec in analysis['recommendations']:
            print(f"   {rec}")
        
        print("="*70)
    
    def save_analysis(self, filename: str = "repository_analysis.json"):
        """Sauvegarde l'analyse en JSON"""
        if not self.analysis_results:
            print("‚ùå Aucune analyse √† sauvegarder")
            return
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(self.analysis_results, f, indent=2, ensure_ascii=False)
            print(f"üíæ Analyse sauvegard√©e: {filename}")
        except Exception as e:
            print(f"‚ùå Erreur sauvegarde: {e}")
    
    def run_complete_analysis(self):
        """Ex√©cute l'analyse compl√®te"""
        print("üöÄ Analyseur Rapide - Framework Pr√©servation S√©mantique")
        print("="*60)
        
        start_time = time.time()
        
        # √âtape 1: Cloner/v√©rifier le repository
        if not self.clone_or_update_repo():
            print("‚ùå Impossible d'obtenir le repository")
            return False
        
        # √âtape 2: Analyser
        print(f"\nüîç Analyse en cours...")
        analysis = self.analyze_repository()
        
        if not analysis:
            print("‚ùå √âchec de l'analyse")
            return False
        
        duration = time.time() - start_time
        
        # √âtape 3: Afficher les r√©sultats
        self.print_analysis_report()
        
        print(f"\n‚è±Ô∏è  Dur√©e totale: {duration:.2f} secondes")
        
        # √âtape 4: Sauvegarder
        self.save_analysis()
        
        # √âtape 5: Prochaines √©tapes
        print(f"\nüöÄ PROCHAINES √âTAPES RECOMMAND√âES")
        print("   1. Examiner les classes TokenPair et Embedding identifi√©es")
        print("   2. Tester l'importation des modules trouv√©s")
        print("   3. Cr√©er l'adaptateur legacy bas√© sur cette analyse")
        print("   4. Impl√©menter les classes enrichies avec h√©ritage")
        
        return True

def main():
    """Point d'entr√©e principal"""
    analyzer = QuickRepositoryAnalyzer()
    
    success = analyzer.run_complete_analysis()
    
    if success:
        print("\n‚úÖ Analyse termin√©e avec succ√®s!")
        print("üìÑ Consultez le fichier 'repository_analysis.json' pour plus de d√©tails")
    else:
        print("\n‚ùå Analyse √©chou√©e")
        print("üí° V√©rifiez votre connexion internet et que Git est install√©")

if __name__ == "__main__":
    main()